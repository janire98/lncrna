ESCRITURA TFM

# INTRODUCCIÓN
El hepatocarcinoma es el tumor primario que causa el 90% de todos los cánceres de hígado. Actualmente, el cáncer de hígado es una de las enfermedades más letales, con una tasa de supervivencia a 5 años del 18% de los pacientes.

En esta introducción, se definirán los aspectos más importantes y generales sobre el hígado, así como los desencadenantes del hepatocarcinoma.

## 1.1 - EL HÍGADO

Es la glándula más grande del organismo y el segundo órgano más grande. La función principal del hígado es procesar los nutrientes absorbidos por el tubo digestivo y almacenarlos para que otros órganos los usen.
Entre otras muchas otras funciones, cabe destacar su capacidad detoxificadora, eliminando sustancias nocivas para el organismo.
 
Su principal componente es el hepatocito, una célula de forma poliédrica que se encuentra en el parénquima hepático y es la responsable de gran parte de las funciones del hígado.

### 1.1.1 - Capacidad regenerativa del hígado
Algunos vertebrados, como las salamandras, pueden regenerar sus extremidades en un proceso que reconstituye tanto la anatomía como la función original sin rastro de cicatriz. En los mamíferos, ocurre algo similar durante la embriogénesis, pero se pierde la mayoría de esa capacidad posteriormente.
Sin embargo, el hígado sí que conserva cierta capacidad regenerativa. Esto es visible durante las hepatectomías parciales, donde se hace una resección del órgano sin que sufra ningún daño. Esto hace que el hígado detecte un tamaño insuficiente y experimente un crecimiento compensatorio.

De igual manera, puede regenerarse cuando sufre un daño por un agente tanto exógeno como endógeno (alcohol, virus de la hepatitis B/C, ácidos grasos…) que producen la muerte de los hepatocitos. En este proceso, hay una reacción inflamatoria y se da la síntesis o remodelación de la matriz extracelular. 
Si el daño persiste en el tiempo, no se daría el proceso de la regeneración, si no que se activaría la reparación. El mecanismo de reparación genera una cicatrización excesiva, denominada fibrosis, lo que modifica la estructura original del hígado e impide su funcionamiento óptimo.
Esto último es lo que sucede en las enfermedades hepáticas crónicas, que pueden derivar en una carcinogénesis.

### 1.1.2 - Factores de riesgo de hepatocarcinoma
El hepatocarcinoma se suele dar en el contexto de una enfermedad hepática crónica. Así pues, el principal factor de riesgo es la cirrosis hepática, un daño crónico e irreversible al hígado que surge como consecuencia de la necrosis de los hepatocitos, en el que se forma tejido cicatricial como resultado de la activación de células estrelladas presentes.
Los otros factores de riesgo que predominan son el abuso del alcohol y las infecciones por los virus de la hepatitis B y C.

Además, el tabaco y la ingesta de la aflatoxina B1 (metabolito fúngico, asociados a mutaciones en el gen supresor de tumores p53) actúan como cofactores que contribuyen en su desarrollo.

Por otro lado, se puede dar HCC en pacientes que no tienen un historial cirrótico, como es el caso de aquellos con esteatohepatitis no alcohólica asociada a obesidad y/o síndrome metabólico. De hecho, es un factor que preocupa, ya que se ha visto un incremento muy significativo de HCC con este origen.


### 1.1.3 - Diagnóstico
El hepatocarcinoma es una enfermedad predominantemente asintomática, por lo que, para cuando aparecen los síntomas, es muy común encontrar al paciente en un estadío avanzado. 
Las técnicas diagnósticas más utilizadas suelen ser no invasivas, como un TAC, ecografía, resonancia magnética… 
Aun así, en la actualidad es muy común realizar biopsias, para así poder tener una mejor caracterización molecular del tumor.

A la vez, se suelen medir algunos parámetros en sangre, como la alfafetoproteína (AFP). Ésta es una proteína sintetizada en el hígado a gran concentración en el primer año de vida de un bebé. Sin embargo, una vez transcurrido ese periodo, la concentración decae al mínimo, por lo que un adulto sano debería tener niveles muy bajos de AFP. 
Niveles superiores de AFP pueden ser signo de diversas patologías, como cáncer de hígado, testículos u ovario, hepatitis o cirrosis. Por eso mismo, es un marcador tumoral muy común en la clínica, puesto que ayuda a detectar las afecciones ya mencionadas.

### 1.1.4 - Tratamiento
La resección hepática y el trasplante son los tratamientos más utilizados a día de hoy para tratar el HCC. En la actualidad, los tratamientos sistémicos son las terapias convencionales utilizadas en HCC, entre las que se incluyen los inhibidores del immune-checkpoint, inhibidores de la tirosina-quinasa y anticuerpos monoclonales.

No obstante, la mayoría de los casos son diagnosticados en estadíos avanzados, donde tan solo pueden aplicarse tratamientos paliativos. Además, las tasas de recurrencia, así como la alta mortalidad, denotan una gran necesidad de encontrar nuevas diana terapéuticas.
Se han descubierto varios drivers para HCC, todos ellos proteínas, pero los fármacos dirigidos a ellos han resultado ineficaces o están implicados en rutas que no pueden ser escogidas como diana.

### 1.1.5- Cribados
El cáncer de hígado se suele detectar en fases tardías, ya que es cuando suelen aparecer los síntomas. Por eso mismo, a pesar de los tratamientos existentes, la tasa de supervivencia es muy baja. Para hacer frente a esto, se plantea el cribado como una medida de detección precoz de la enfermedad en pacientes cirróticos, puesto que son los que más riesgo tienen de desarrollar HCC.
Para ello, se realizó un ensayo clínico que verificó la utilidad de realizar una ecografía cada 6 meses a estos pacientes, mejorando su tasa de supervivencia. 
Los individuos beneficiados del cribado fueron los pacientes cirróticos en clase funcional Child-Pugh A y B, mientras que no es útil realizarlo en pacientes en los que el trasplante está contraindicado.

### 1.1.6 - RNAs largos no codificantes (lncRNA)
Los RNAs largos no codificantes son secuencias de más de 200 nucleótidos que no son traducidas a proteína. Cuantitativamente hablando, se expresan en niveles mucho más bajos que los protein-coding genes, y se estima que hay hasta 100.000 genes de lncRNA. En la actualidad, están empezando a ser muy estudiados, 
ya que pueden formar estructuras secundarias y terciarias, uniéndose al RNA, DNA o a las proteínas y regular la función proteica y la expresión génica a diferentes niveles. 
De hecho, se ha descubierto la existencia de lncRNA que se traducen a micropéptidos con funciones en la iniciación y progresión del cáncer.
En adición, son específicos de tejido, cualidad interesante para que sean considerados como potenciales biomarcadores y dianas terapéuticas.

### 1.1.7 - Bioinformática y Ciencia de Datos
Con las nuevas tecnologías, se ha experimentado un incremento exponencial en la generación de datos biomédicos. Tal es así, que en la actualidad se ha vuelto indispensable el uso de métodos computacionales para poder extraer la información biomédica









# METODOLOGÍA
## 3.1 - Muestras
Las muestras utilizadas en este trabajo pertenecen al proyecto NASIR, un ensayo clínico de medicamento realizado a nivel nacional, financiado por la farmacéutica BRISTOL-MYERS SQUIBB PHARMA EEIG y patrocinado por la Clínica Universidad de Navarra.
El ensayo clínico cuenta con 30 pacientes con HCC a los que se les realizó una biopsia del tumor, secuenciados mediante la tecnología RNA-Seq, que permite estudiar la expresión de los genes.
El análisis RNA-Seq contiene varios pasos, que van desde la preparación de las librerías hasta el análisis bioinformático, que es el que se detallará a continuación.
Además de los datos de RNA-Seq, son de interés los datos de supervivencia de los pacientes.

## 3.2 - Análisis de datos
Se secuencian las muestras para obtener las lecturas. El fichero resultante es un FASTQ, que contiene los nucleótidos asociados a una letra que determina la calidad de secuenciación de cada uno de ellos.

## 3.3- Calidad de las secuencias
El primer paso una vez obtenidas las secuencias, es evaluar la calidad de éstas y ver si hay que reducir el ruido, que puede venir de la propia secuenciación o de la contaminación de la muestra.
Se puede aproximar la calidad de los nucleótidos ya que los sistemas de secuenciación calculan la probabilidad de que el nucleótido identificado sea erróneo. Esta aproximación la calcula el software de la máquina utilizando la escala Phred, es específica de cada tecnología.
Se eliminan las lecturas con adaptadores y aquellas en las que la calidad sea baja. 
Se comprueba la calidad con la herramienta FASTQC.

## 3.4- Alineamiento de las lecturas
Una vez pasado el control de calidad, las lecturas se mapean contra el genoma humano de referencia "gencode.v29.annotation.gtf" utilizando Subread, una herramienta que alinea datos genómicos de DNA-Seq y RNA-Seq.
El archivo obtenido del alineamiento es en formato .BAM.

## 3.5 - Cuantificación
Para medir los niveles de expresión de los genes, se utiliza FeatureCounts, un software informático que cuantifica el número de lecturas alineadas con cada uno de los genes y que devuelve conteos.

## 3.6 - Normalización
Los conteos obtenidos tienen un sesgo técnico que se debe a múltiples factores. Entre ellos, al diferente tamaño de las secuencias de RNA y a que han sido secuenciadas a diferente profundidad, que ha de ser corregido mediante la normalización.
Existen numerosos métodos de normalización, por lo que hay que elegir el más adecuado acorde a las necesidades de estudio. Se van a mostrar algunos de los considerados para la realización de este trabajo:
Normalización por TPM (transcripts per killobase million): normaliza las cuentas por largura del tránscrito por millón. Necesita la profundidad de secuenciación y la largura del gen. Este método es adecuado para comparar los genes de una misma muestra o para comparar genes entre muestras de un mismo grupo. No sirve para hacer un análisis de expresión diferencial.
Es el método de normalización por defecto de algunas herramientas, como Sleuth.
Normalización de DESeq2 (método de mediana de ratios) : normaliza las cuentas por diferencias en el tamaño y composición de la librería. A continuación se detalla cómo normaliza:
1. Tomar los logaritmos en base e de todos los valores (loge). 
2. Coge el promedio de cada uno de los genes. La ventaja de utilizar el promedio de los logaritmos es que los outliers no modifican en exceso el promedio de los genes.
3. Filtra los genes que tienen valores logarítmicos de infinito.
4. Extrae el valor logarítmico promedio del logaritmo de las cuentas.
5. Calcula la mediana de los ratios para cada muestra
6. Convierte las medianas en “valores normales” para obtener los factores de escala finales para cada muestra.
7. Divide las cuentas originales por los factores de escala.
DESeq2 cuenta con una transformación denominada “Regularized log” o “rlog”, que transforma las cuentas en escala log2 de una manera que minimiza las diferencias entre muestras en las que los genes tienen pocas cuentas. Es similar a otra, denominada “variance Stabilizing Transformation”, solo que más robusto si los factores de tamaño varían de forma amplia.
Es un método que puede ser utilizado para encontrar valores atípicos, así como input en diversas técnicas de machine learning, como un clustering.

## 3.7- Filtrado de genes
Hasta el momento, se han conservado tanto los lncRNA como los protein-coding genes. A su vez, los lncRNA se expresan menos que los protein-coding pero, de igual manera, hay que establecer filtros para que queden los genes más robustos.

### 3.7.1- Filtro de todos los genes a lncRNA
Se escoge la versión del transcriptoma exclusivo de lncRNA de la web de Gencode, que está en formato GTF.
Se mantienen únicamente aquellos genes que concuerden con los existentes en este transcriptoma.

### 3.7.2- Filtros ad-hoc
Los filtros ad-hoc van a ser de utilidad para eliminar genes que no son útiles, si no que solo generan ruido.
Se calculan el máximo y la desviación estándar para cada uno de los genes, estableciéndose como criterio de filtrado:
Sólo se mantienen los genes que tengan un máximo igual o superior a 50
Sólo se mantienen los genes que tengan una desviación estándar igual o superior a 10.
Se mantienen únicamente los genes que tengan al menos 10 counts en un mínimo de 5 pacientes (16% del total)

Una vez hechos todos los filtros, se establece que 3120 genes pasan el corte.

### 3.7.3 - Genes NICO
Como filtro adicional, se genera un data frame nuevo con un listado de genes con especial interés para el laboratorio, denominados NICO.
Estos NICO se filtran una vez se ha realizado el siguiente paso, el reescalado de los genes.

## 3.8 - Reescalado de genes
Una vez filtrado los genes, se hace un reescalado del 1 al 30. Antes de eso, se hace un escalado previo:
Se transpone la matriz para que los genes queden como features.
Se escalan los datos en base a los genes.
Se vuelve a transponer la matriz para que adopte la forma inicial, con las muestras como features.
Por último, para reescalar de 1 a 30 , se utiliza la función “rescale” de la librería “scales” de R.

### 3.8.1 - NICO
Una vez reescalados los genes, se extraen de este dataset los genes NICO.

## 3.9 - Clustering de los genes
Se han hecho diferentes intentos en este apartado.

### 3.9.1- Clustering general 

#### 3.9.1.1 - K-means
K-means es un algoritmo no supervisado de Machine Learning que agrupa los datos según sus características.
El algoritmo realiza tres pasos:
Una vez el usuario asigna el número de grupos o clusters que desea(k), el algoritmo establece k centroides de forma aleatoria.
Se asigna cada uno de los valores al centroide más cercano.
Se calcula el promedio de cada grupo y el resultado pasa a ser el nuevo centroide del grupo.
Se repiten los pasos 2 y 3 hasta que los centroides no se muevan por encima de un umbral. 
De hecho, k-means minimiza la función de la suma de las distancias cuadráticas de cada uno de los datos al centroide de su grupo.
El resultado es un ajuste que maximiza la distancia entre grupos y minimiza la distancia intragrupal.


#### 3.9.1.2 - Hierarchical clustering
El clustering jerárquico es un método de Data Mining para clasificar datos que se basa en la distancia entre los propios datos, agrupando aquellos que sean más similares entre sí. Al igual que K-means, es un método de aprendizaje no supervisado.

Los elementos se muestran de manera visual en un árbol anidado de manera jerarquizada
-----------------------------------------------------------------


En este proyecto se utiliza el hierarchical clustering para realizar las agrupaciones. Sin embargo, se da de varias formas:

##### 3.9.1.2.1 - Clustering general
Se utiliza el dataset completo para realizar la división de grupos. El número de grupos en los que se divide, va de un rango de 2 clusters a 50. Cada uno de los resultados se guarda en una carpeta diferente, que posteriormente será analizada para la supervivencia.

Como contrapartida de este método, es que se está forzando al algoritmo a realizar particiones que no están tan claras, pudiendo dar lugar a incorrectas agrupaciones de genes.

##### 3.9.1.2.2 - Sub Clustering
Otra forma de dividir los clusters es coger el dataset original y hacerles una partición inicial con el número de clusters recomendado por las pruebas Silhouette o Wss, para así coger cada uno de los fragmentos y realizarles clustering jerárquicos sucesivos (siguiendo las mismas particiones), hasta conseguir grupos del número de genes máximo deseado. 
En este caso, se ha establecido que los clusters tendrán un máximo de 50 genes.

##### 3.9.1.2.3 - Genes NICO
Para el data frame de los genes NICO el criterio difiere, ya que es un dataset mucho menor. Así pues, se establece que los grupos han de tener un máximo de 15 genes.



## 3.10 - Análisis de supervivencia

Los análisis de supervivencia son un conjunto de técnicas estadísticas que estudian la relación entre una variable y el tiempo que tarda en suceder un evento. Ésta puede tener una relación casual o estar directamente relacionada con dicho evento. 
Para realizarlo, se necesita el tiempo de seguimiento, así como una variable que indique si sucede un evento o no.

El tiempo 0 se da cuando el paciente ingresa en el estudio y el seguimiento termina una vez se de el evento o llegue la fecha de cierre del estudio. Cuando el individuo abandona el estudio sin que suceda el evento en cuestión ni haya finalizado el tiempo de seguimiento, se obtiene una información parcial y se dice que el individuo está censurado. Cabe destacar que las fechas de inicio y finalización del estudio son diferentes en cada paciente porque se incorporan en momentos diferentes.
Tanto el estado inicial como el evento deben definirse a la perfección para saber con exactitud las fechas. En este proyecto, el evento en cuestión es el fallecimiento del paciente.
Aquí se mide la supervivencia, que se define como la probabilidad de que el evento no ocurra en  un tiempo determinado “t”, es decir, es la probabilidad de que un paciente sobreviva.
Se pueden utilizar tanto métodos paramétricos como no paramétricos, aunque lo habitual es utilizar los no paramétricos porque la distribución de tiempo de supervivencia suele ser desconocida debido a la falta de información.

Método de Kaplan-Meier
Es el método no paramétrico utilizado para estimar la probabilidad de supervivencia y se asume que el evento es independiente para cada paciente. 
La probabilidad de vivir en un tiempo “t” se calcula con la ley multiplicativa de las probabilidades.
En la gráfica, además de la probabilidad de supervivencia, se muestra la mediana, es decir, a qué tiempo corresponde un 0.5 de probabilidades de sobrevivir, ya que no hace falta conocer el tiempo de todos los pacientes, mientras que, si se utilizase la media, sí.

Por otro lado, la función de riesgo, que indica la probabilidad de que a un paciente le ocurra el evento a tiempo “t”,  puede ser muy útil para describir la dinámica de lo que se quiere estudiar.

En este proyecto se van a realizar en tres ocasiones el análisis de supervivencia con el método de Kaplan-Meier:
De los clusters iniciales generales. Se quiere ver si los grupos grandes arrojan resultados significativos en la supervivencia, donde se podrá ver si en determinado cluster hay una gran cantidad de genes involucrados en la supervivencia.
De los sub-clusters generados en particiones sucesivas, que cuentan con 50 genes o menos. 
De las combinaciones binarias de genes que han arrojado resultados significativos en el análisis de los sub-clusters, para determinar cuáles están involucrados en ese resultado significativo.
Se consideran significativos aquellos análisis de supervivencia en los que el p-valor sea igual o menor a 0.05 y tenga al menos un 20% de los pacientes en cada grupo (6 pacientes).









# 4.- RESULTADOS
Filtrado de genes
De los 58721 genes iniciales, 12308 son considerados lncRNA.
Una vez realizados los filtros ad-hoc anteriormente explicados, pasan todos los filtros 3120 genes.

Clusterings
Clustering general
Sobre el dataset original se realizan 49 pruebas, cada una de ellas con una partición que va desde los 2 clusters hasta los 50. Así pues, se obtienen 49 carpetas, con 2, 3, 4……,48, 49 y 50  clusters.


Sub Clustering
Utilizando el dataset con 3120 genes, se realizan clusterings sucesivos hasta obtener grupos de 50 genes o menos. En total, se han generado 196 clusters.

Nico
A los genes NICO se les realiza un clustering en el que el máximo de genes por grupo sea de 15.

Análisis de supervivencia
Del clustering general
Ningún cluster cumple todos los criterios especificados para considerarlo estadísticamente significativo en la supervivencia.
Sin embargo, si se elimina el mínimo de pacientes en cada grupo, sí se puede observar un patrón

Análisis de los sucesivos clusters o Sub clusters
Se utilizan los 196 clusters como input para el análisis de supervivencia y se dividen los pacientes en dos grupos (también por clustering jerárquico), high- y low-risk.
De los 196 clusters, 3 arrojaron resultados estadísticamente significativos en la supervivencia:
El cluster número 72, que se compone de 2 genes: RP11-1246C19.1 y RP11-417L19.6
El cluster número 172, que se compone de 12 genes: AC011247.3, AC008937.2, RP11-702F3.1, RP11-705C15.3, RP11-530C5.2, RP11-16B9.1, RP11-151N17.1, RP11-380M21.4, RP11-797A18.6, JMJD1C-AS1, RP11-218F10.3 y  RP11-797A18.5
El cluster número 177, que se compone de 9 genes: RP5-1142A6.8, CFLAR-AS1, CDC42-IT1, MYCBP2-AS1, RP11-894P9.1, RP11-840I19.3, RP11-103B5.4, CTD-2574D22.3 y RP11-463O12.5





